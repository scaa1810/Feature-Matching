import cv2
import numpy as np

# Load static image with validation
static_image = cv2.imread("/home/aaliya/Desktop/kachow/feature matching/testimg1.png")
static_image = cv2.resize(static_image, (288, 352))
if static_image is None:
    raise FileNotFoundError("Static image not found at specified path")

static_image_gray = cv2.cvtColor(static_image, cv2.COLOR_BGR2GRAY)

# ORB detector with enhanced parameters
orb = cv2.ORB_create(
    nfeatures=500,
    scaleFactor=1.2,
    edgeThreshold=15,
    patchSize=31
)

# FLANN configuration optimized for real-time matching
FLANN_INDEX_LSH = 6
index_params = dict(
    algorithm=FLANN_INDEX_LSH,
    table_number=6,
    key_size=12,
    multi_probe_level=2
)
search_params = dict(checks=100)
flann = cv2.FlannBasedMatcher(index_params, search_params)

# Detect features in static image
kp1, des1 = orb.detectAndCompute(static_image_gray, None)

# Video capture setup with proper resolution
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while True:
    ret, live_frame = cap.read()
    if not ret:
        break

    live_frame = cv2.resize(live_frame, (288, 352))
    live_frame = cv2.flip(live_frame, 1)
    live_frame_gray = cv2.cvtColor(live_frame, cv2.COLOR_BGR2GRAY)
    
    # Feature detection in live frame
    kp2, des2 = orb.detectAndCompute(live_frame_gray, None)
    
    if des2 is None or des1 is None:
        continue

    # Feature matching with FLANN
    matches = flann.knnMatch(des1, des2, k=2)

    # Lowe's ratio test with adaptive threshold
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    # Homography estimation with RANSAC
    if len(good_matches) >= 10:  # Increased minimum matches for better stability
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)
        
        # RANSAC parameters:
        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0, confidence=0.99, maxIters=2000)#5.0=pixel reprojection threshold
        
        if H is not None and not np.isnan(H).any():
            # Draw transformed bounding box
            h, w = static_image_gray.shape
            corners = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0]]).reshape(-1,1,2)
            
            try:
                transformed_corners = cv2.perspectiveTransform(corners, H)
                live_frame = cv2.polylines(live_frame, [np.int32(transformed_corners)], True, (0,255,0), 3)
                
                # Draw only inlier matches
                inlier_matches = [m for m, keep in zip(good_matches, mask) if keep]
                matched_image = cv2.drawMatches(static_image, kp1, live_frame, kp2, inlier_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
            except cv2.error as e:
                print(f"Homography error: {str(e)}")
                matched_image = cv2.drawMatches(static_image, kp1, live_frame, kp2,good_matches, None)
        else:
            matched_image = cv2.drawMatches(static_image, kp1, live_frame, kp2,good_matches, None)
    else:
        matched_image = cv2.drawMatches(static_image, kp1, live_frame, kp2,good_matches, None)

    cv2.imshow("Matches", matched_image)
    
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
